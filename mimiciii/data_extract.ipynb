{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mimic3benchmark.readers import InHospitalMortalityReader\n",
    "from mimic3models import common_utils\n",
    "from mimic3models.in_hospital_mortality.utils import save_results\n",
    "from mimic3models.metrics import print_metrics_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_extract_features(reader, period, features):\n",
    "    ret = common_utils.read_chunk(reader, reader.get_number_of_examples())\n",
    "    # ret = common_utils.read_chunk(reader, 100)\n",
    "    X = common_utils.extract_features_from_rawdata(ret['X'], ret['header'], period, features)\n",
    "    return (X, ret['y'], ret['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat basic data file and index file\n",
    "train_reader = InHospitalMortalityReader(dataset_dir='data/in-hospital-mortality/train',\n",
    "                                             listfile='data/in-hospital-mortality/train_listfile.csv',\n",
    "                                             period_length=48.0)\n",
    "val_reader = InHospitalMortalityReader(dataset_dir='data/in-hospital-mortality/train',\n",
    "                                             listfile='data/in-hospital-mortality/val_listfile.csv',\n",
    "                                           period_length=48.0)\n",
    "test_reader = InHospitalMortalityReader(dataset_dir='data/in-hospital-mortality/test',\n",
    "                                             listfile='data/in-hospital-mortality/test_listfile.csv',\n",
    "                                            period_length=48.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "(_, train_y, train_names) = read_and_extract_features(train_reader, 'all', 'all')\n",
    "(_, val_y, val_names) = read_and_extract_features(val_reader, 'all', 'all')\n",
    "(_, test_y, test_names) = read_and_extract_features(test_reader, 'all', 'all')\n",
    "columns = ['PID','age','SBPmin','SBPmax','Tempmin','Tempmax','Respmin','Respmax','ABEmin','ABEmax','Lacmin','Lacmax','SBEmin','SBEmax','pCO2','pO2','K','HCO3','sO2','PC','PCT','Glu','SBC','M_label']\n",
    "test_data=pd.DataFrame(columns=columns)\n",
    "train_data=pd.DataFrame(columns=columns)\n",
    "val_data=pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common features of patients\n",
    "\n",
    "# create test data\n",
    "i=0\n",
    "for file in test_names:\n",
    "    \n",
    "    #age\n",
    "    PID=(file.split('_'))[0]\n",
    "    if os.path.exists('data/root/test/'+PID+'/episode1.csv'):\n",
    "        path='data/root/test/'+PID+'/episode1.csv'\n",
    "    elif os.path.exists('data/root/test/'+PID+'/episode2.csv'):\n",
    "        path='data/root/test/'+PID+'/episode2.csv'\n",
    "    elif os.path.exists('data/root/test/'+PID+'/episode3.csv'):\n",
    "        path='data/root/test/'+PID+'/episode3.csv'\n",
    "    elif os.path.exists('data/root/test/'+PID+'/episode4.csv'):\n",
    "        path='data/root/test/'+PID+'/episode4.csv'\n",
    "    elif os.path.exists('data/root/test/'+PID+'/episode5.csv'):\n",
    "        path='data/root/test/'+PID+'/episode5.csv'\n",
    "    age = pd.read_csv(path)\n",
    "    \n",
    "    #events\n",
    "    df = pd.read_csv('data/in-hospital-mortality/test/'+file)\n",
    "    data=[PID,age['Age'][0],df['Systolic blood pressure'].min(),df['Systolic blood pressure'].max(),df['Temperature'].min(),df['Temperature'].max(),df['Respiratory rate'].min(),df['Respiratory rate'].max(),np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,df['Oxygen saturation'].min(),np.NaN,np.NaN,df['Glucose'].max(),np.NaN,test_y[i]]\n",
    "    test_data.loc[i]=data\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "# create train data\n",
    "i=0\n",
    "for file in train_names:\n",
    "    \n",
    "    PID=(file.split('_'))[0]\n",
    "    if os.path.exists('data/root/train/'+PID+'/episode1.csv'):\n",
    "        path='data/root/train/'+PID+'/episode1.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode2.csv'):\n",
    "        path='data/root/train/'+PID+'/episode2.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode3.csv'):\n",
    "        path='data/root/train/'+PID+'/episode3.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode4.csv'):\n",
    "        path='data/root/train/'+PID+'/episode4.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode5.csv'):\n",
    "        path='data/root/train/'+PID+'/episode5.csv'\n",
    "    age = pd.read_csv(path)\n",
    "    \n",
    "    df = pd.read_csv('data/in-hospital-mortality/train/'+file)\n",
    "    data=[PID,age['Age'][0],df['Systolic blood pressure'].min(),df['Systolic blood pressure'].max(),df['Temperature'].min(),df['Temperature'].max(),df['Respiratory rate'].min(),df['Respiratory rate'].max(),np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,df['Oxygen saturation'].min(),np.NaN,np.NaN,df['Glucose'].max(),np.NaN,train_y[i]]\n",
    "    train_data.loc[i]=data\n",
    "    i+=1\n",
    "\n",
    "# create val data\n",
    "i=0\n",
    "for file in val_names:\n",
    "    PID=(file.split('_'))[0]\n",
    "    if os.path.exists('data/root/train/'+PID+'/episode1.csv'):\n",
    "        path='data/root/train/'+PID+'/episode1.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode2.csv'):\n",
    "        path='data/root/train/'+PID+'/episode2.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode3.csv'):\n",
    "        path='data/root/train/'+PID+'/episode3.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode4.csv'):\n",
    "        path='data/root/train/'+PID+'/episode4.csv'\n",
    "    elif os.path.exists('data/root/train/'+PID+'/episode5.csv'):\n",
    "        path='data/root/train/'+PID+'/episode5.csv'\n",
    "    age = pd.read_csv(path)\n",
    "    \n",
    "    df = pd.read_csv('data/in-hospital-mortality/train/'+file)\n",
    "    data=[PID,age['Age'][0],df['Systolic blood pressure'].min(),df['Systolic blood pressure'].max(),df['Temperature'].min(),df['Temperature'].max(),df['Respiratory rate'].min(),df['Respiratory rate'].max(),np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,np.NaN,df['Oxygen saturation'].min(),np.NaN,np.NaN,df['Glucose'].max(),np.NaN,val_y[i]]\n",
    "    val_data.loc[i]=data\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "# from uncommon features of patients\n",
    "\n",
    "# Base Excess (ABE/SBE) 50802\n",
    "# Lactate 50813\n",
    "# pCO2 50818\n",
    "# pO2 50821\n",
    "# Potassium 50833\n",
    "# HCO3 50803\n",
    "# Platelet count / Plateletrit 51265\n",
    "# Bicarbonate (Standard Bicarbonate) 50882\n",
    "\n",
    "# remove the same items\n",
    "\n",
    "# Base Excess / ABE/ SBE 50802\n",
    "# Platelet count / Plateletrit 51265\n",
    "test_data.drop(['SBEmin','SBEmax','PCT'],axis=1,inplace=True)\n",
    "val_data.drop(['SBEmin','SBEmax','PCT'],axis=1,inplace=True)\n",
    "train_data.drop(['SBEmin','SBEmax','PCT'],axis=1,inplace=True)\n",
    "\n",
    "# add single-value items\n",
    "eventID=[50802,50813,50818,50821,50833,50803,51265,50882]\n",
    "\n",
    "i=0\n",
    "for file in val_names:\n",
    "    PID=(file.split('_'))[0]\n",
    "    path='data/root/train/'+PID+'/events.csv'\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    val_data['ABEmin'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].min()\n",
    "    val_data['ABEmax'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].max()\n",
    "    \n",
    "    val_data['Lacmin'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].min()\n",
    "    val_data['Lacmax'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].max()\n",
    "    \n",
    "    val_data['pCO2'][i]=data[data['ITEMID']==eventID[2]]['VALUE'].max()\n",
    "    \n",
    "    val_data['pO2'][i]=data[data['ITEMID']==eventID[3]]['VALUE'].min()\n",
    "    \n",
    "    val_data['K'][i]=data[data['ITEMID']==eventID[4]]['VALUE'].max()\n",
    "    \n",
    "    val_data['HCO3'][i]=data[data['ITEMID']==eventID[5]]['VALUE'].min()\n",
    "    \n",
    "    val_data['PC'][i]=data[data['ITEMID']==eventID[6]]['VALUE'].max()\n",
    "    \n",
    "    val_data['SBC'][i]=data[data['ITEMID']==eventID[7]]['VALUE'].min()\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "\n",
    "i=0\n",
    "for file in test_names:\n",
    "    PID=(file.split('_'))[0]\n",
    "    path='data/root/test/'+PID+'/events.csv'\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    test_data['ABEmin'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].min()\n",
    "    test_data['ABEmax'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].max()\n",
    "    \n",
    "    test_data['Lacmin'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].min()\n",
    "    test_data['Lacmax'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].max()\n",
    "    \n",
    "    test_data['pCO2'][i]=data[data['ITEMID']==eventID[2]]['VALUE'].max()\n",
    "    \n",
    "    test_data['pO2'][i]=data[data['ITEMID']==eventID[3]]['VALUE'].min()\n",
    "    \n",
    "    test_data['K'][i]=data[data['ITEMID']==eventID[4]]['VALUE'].max()\n",
    "    \n",
    "    test_data['HCO3'][i]=data[data['ITEMID']==eventID[5]]['VALUE'].min()\n",
    "    \n",
    "    test_data['PC'][i]=data[data['ITEMID']==eventID[6]]['VALUE'].max()\n",
    "    \n",
    "    test_data['SBC'][i]=data[data['ITEMID']==eventID[7]]['VALUE'].min()\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "i=0\n",
    "for file in train_names:\n",
    "    PID=(file.split('_'))[0]\n",
    "    path='data/root/train/'+PID+'/events.csv'\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    train_data['ABEmin'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].min()\n",
    "    train_data['ABEmax'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].max()\n",
    "    \n",
    "    train_data['Lacmin'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].min()\n",
    "    train_data['Lacmax'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].max()\n",
    "    \n",
    "    train_data['pCO2'][i]=data[data['ITEMID']==eventID[2]]['VALUE'].max()\n",
    "    \n",
    "    train_data['pO2'][i]=data[data['ITEMID']==eventID[3]]['VALUE'].min()\n",
    "    \n",
    "    train_data['K'][i]=data[data['ITEMID']==eventID[4]]['VALUE'].max()\n",
    "    \n",
    "    train_data['HCO3'][i]=data[data['ITEMID']==eventID[5]]['VALUE'].min()\n",
    "    \n",
    "    train_data['PC'][i]=data[data['ITEMID']==eventID[6]]['VALUE'].max()\n",
    "    \n",
    "    train_data['SBC'][i]=data[data['ITEMID']==eventID[7]]['VALUE'].min()\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "\n",
    "i=0\n",
    "for file in train_names:\n",
    "    PID=(file.split('_'))[0]\n",
    "    path='data/root/train/'+PID+'/events.csv'\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    # pass type error\n",
    "    try:\n",
    "        train_data['ABEmin'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].min()\n",
    "        train_data['ABEmax'][i]=data[data['ITEMID']==eventID[0]]['VALUE'].max()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train_data['Lacmin'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].min()\n",
    "        train_data['Lacmax'][i]=data[data['ITEMID']==eventID[1]]['VALUE'].max()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train_data['pCO2'][i]=data[data['ITEMID']==eventID[2]]['VALUE'].max()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train_data['pO2'][i]=data[data['ITEMID']==eventID[3]]['VALUE'].min()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train_data['K'][i]=data[data['ITEMID']==eventID[4]]['VALUE'].max()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train_data['HCO3'][i]=data[data['ITEMID']==eventID[5]]['VALUE'].min()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train_data['PC'][i]=data[data['ITEMID']==eventID[6]]['VALUE'].max()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train_data['SBC'][i]=data[data['ITEMID']==eventID[7]]['VALUE'].min()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14681, 21)\n",
      "(3222, 21)\n",
      "(3236, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)\n",
    "test_data.to_csv('mimiciii_data/test_data.csv')\n",
    "val_data.to_csv('mimiciii_data/val_data.csv')\n",
    "train_data.to_csv('mimiciii_data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
